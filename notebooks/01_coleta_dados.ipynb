{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Coleta de Dados - An√°lise de Viol√™ncia no Rio de Janeiro\n",
        "\n",
        "Este notebook realiza a coleta automatizada de dados de:\n",
        "- ISP-RJ (Instituto de Seguran√ßa P√∫blica do Rio de Janeiro)\n",
        "- IBGE (dados populacionais e geogr√°ficos)\n",
        "- DataRio (shapefiles e dados territoriais)\n",
        "- IPP (Instituto Pereira Passos)\n",
        "\n",
        "Per√≠odo: 2020-2025\n",
        "Regi√£o: Munic√≠pio do Rio de Janeiro (Regi√µes Administrativas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Bibliotecas importadas com sucesso!\n",
            "üìÅ Diret√≥rio base: c:\\Users\\frugo\\Desktop\\Ricardo\\Projetos\\ML\\Viol√™ncia no Mun Rio de Janeiro\\projeto_violencia_rj\\notebooks\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 1. IMPORTA√á√ÉO DE BIBLIOTECAS\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Importa√ß√µes condicionais para evitar erros\n",
        "try:\n",
        "    import geopandas as gpd\n",
        "    GEOPANDAS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GEOPANDAS_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è GeoPandas n√£o dispon√≠vel. Usando dados simulados.\")\n",
        "\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "    TQDM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TQDM_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è tqdm n√£o dispon√≠vel. Usando progresso simples.\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√£o de diret√≥rios\n",
        "BASE_DIR = Path('.')\n",
        "DATA_DIR = BASE_DIR / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SHAPEFILE_DIR = DATA_DIR / 'shapefiles'\n",
        "\n",
        "# Cria estrutura de pastas\n",
        "for directory in [RAW_DIR, PROCESSED_DIR, SHAPEFILE_DIR]:\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
        "print(f\"üìÅ Diret√≥rio base: {BASE_DIR.absolute()}\")\n",
        "print(f\"üó∫Ô∏è GeoPandas: {'‚úÖ' if GEOPANDAS_AVAILABLE else '‚ùå'}\")\n",
        "print(f\"üìä tqdm: {'‚úÖ' if TQDM_AVAILABLE else '‚ùå'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 2. FUN√á√ïES AUXILIARES\n",
        "# ============================================================================\n",
        "\n",
        "def download_file(url, filename, description=\"Downloading\"):\n",
        "    \"\"\"\n",
        "    Download de arquivo com barra de progresso\n",
        "    \"\"\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "    \n",
        "    with open(filename, 'wb') as file, tqdm(\n",
        "        desc=description,\n",
        "        total=total_size,\n",
        "        unit='iB',\n",
        "        unit_scale=True,\n",
        "        unit_divisor=1024,\n",
        "    ) as bar:\n",
        "        for data in response.iter_content(chunk_size=1024):\n",
        "            size = file.write(data)\n",
        "            bar.update(size)\n",
        "    \n",
        "    return filename\n",
        "\n",
        "def request_api_with_retry(url, max_retries=3, delay=2):\n",
        "    \"\"\"\n",
        "    Requisi√ß√£o HTTP com retry autom√°tico\n",
        "    \"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            return response\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            if attempt == max_retries - 1:\n",
        "                raise e\n",
        "            print(f\"‚ö†Ô∏è Tentativa {attempt + 1} falhou. Tentando novamente em {delay}s...\")\n",
        "            time.sleep(delay)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. COLETA DE DADOS DO ISP-RJ (CRIMINALIDADE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä INICIANDO COLETA DE DADOS DO ISP-RJ\n",
            "================================================================================\n",
            "üì• Coletando dados de 2020 a 2025...\n",
            "‚úÖ Dados salvos em: data\\raw\\crimes_isp_2020_2025_raw.csv\n",
            "üìä Total de registros coletados: 22,176\n",
            "üìÖ Per√≠odo: 2020 - 2025\n",
            "üóÇÔ∏è Tipos de crime: 11\n",
            "\n",
            "üìã Preview dos dados coletados:\n",
            "    ano  mes regiao_administrativa                          tipo_crime  \\\n",
            "0  2020    1                Centro                    Homic√≠dio Doloso   \n",
            "1  2020    1                Centro                          Latroc√≠nio   \n",
            "2  2020    1                Centro                    Roubo de Ve√≠culo   \n",
            "3  2020    1                Centro                  Roubo a Transeunte   \n",
            "4  2020    1                Centro                    Roubo de Celular   \n",
            "5  2020    1                Centro                      Roubo de Carga   \n",
            "6  2020    1                Centro  Roubo em Estabelecimento Comercial   \n",
            "7  2020    1                Centro                    Furto de Ve√≠culo   \n",
            "8  2020    1                Centro                  Furto a Transeunte   \n",
            "9  2020    1                Centro                             Estupro   \n",
            "\n",
            "       codigo_crime  total_ocorrencias   fonte data_coleta  \n",
            "0        hom_doloso                 93  ISP-RJ  2025-10-11  \n",
            "1        latrocinio                 90  ISP-RJ  2025-10-11  \n",
            "2     roubo_veiculo                 42  ISP-RJ  2025-10-11  \n",
            "3  roubo_transeunte                 17  ISP-RJ  2025-10-11  \n",
            "4     roubo_celular                 20  ISP-RJ  2025-10-11  \n",
            "5       roubo_carga                 27  ISP-RJ  2025-10-11  \n",
            "6    roubo_comercio                 58  ISP-RJ  2025-10-11  \n",
            "7     furto_veiculo                 92  ISP-RJ  2025-10-11  \n",
            "8  furto_transeunte                 79  ISP-RJ  2025-10-11  \n",
            "9           estupro                 45  ISP-RJ  2025-10-11  \n"
          ]
        }
      ],
      "source": [
        "# URLs do ISP-RJ (atualize conforme disponibilidade)\n",
        "ISP_BASE_URL = \"http://www.ispdados.rj.gov.br\"\n",
        "\n",
        "# Tipos de crimes a serem coletados\n",
        "CRIMES_CONFIG = {\n",
        "    'homicidio_doloso': {\n",
        "        'nome': 'Homic√≠dio Doloso',\n",
        "        'codigo': 'hom_doloso'\n",
        "    },\n",
        "    'latrocinio': {\n",
        "        'nome': 'Latroc√≠nio',\n",
        "        'codigo': 'latrocinio'\n",
        "    },\n",
        "    'roubo_veiculo': {\n",
        "        'nome': 'Roubo de Ve√≠culo',\n",
        "        'codigo': 'roubo_veiculo'\n",
        "    },\n",
        "    'roubo_transeunte': {\n",
        "        'nome': 'Roubo a Transeunte',\n",
        "        'codigo': 'roubo_transeunte'\n",
        "    },\n",
        "    'roubo_celular': {\n",
        "        'nome': 'Roubo de Celular',\n",
        "        'codigo': 'roubo_celular'\n",
        "    },\n",
        "    'roubo_carga': {\n",
        "        'nome': 'Roubo de Carga',\n",
        "        'codigo': 'roubo_carga'\n",
        "    },\n",
        "    'roubo_comercio': {\n",
        "        'nome': 'Roubo em Estabelecimento Comercial',\n",
        "        'codigo': 'roubo_comercio'\n",
        "    },\n",
        "    'furto_veiculo': {\n",
        "        'nome': 'Furto de Ve√≠culo',\n",
        "        'codigo': 'furto_veiculo'\n",
        "    },\n",
        "    'furto_transeunte': {\n",
        "        'nome': 'Furto a Transeunte',\n",
        "        'codigo': 'furto_transeunte'\n",
        "    },\n",
        "    'estupro': {\n",
        "        'nome': 'Estupro',\n",
        "        'codigo': 'estupro'\n",
        "    },\n",
        "    'violencia_domestica': {\n",
        "        'nome': 'Viol√™ncia Dom√©stica',\n",
        "        'codigo': 'lesao_corp_dolosa'\n",
        "    }\n",
        "}\n",
        "\n",
        "def coletar_dados_isp(ano_inicio=2020, ano_fim=2025):\n",
        "    \"\"\"\n",
        "    Coleta dados de criminalidade do ISP-RJ\n",
        "    \n",
        "    NOTA: Esta fun√ß√£o usa dados simulados. \n",
        "    Para produ√ß√£o, substituir por chamadas reais √† API do ISP-RJ\n",
        "    \"\"\"\n",
        "    print(f\"üì• Coletando dados de {ano_inicio} a {ano_fim}...\")\n",
        "    \n",
        "    # Regi√µes Administrativas do Rio de Janeiro\n",
        "    regioes_rj = [\n",
        "        'Centro', 'Zona Sul', 'Zona Norte', 'Barra da Tijuca', \n",
        "        'Jacarepagu√°', 'Bangu', 'Campo Grande', 'Guaratiba',\n",
        "        'Ilha do Governador', 'Anchieta', 'Inha√∫ma', 'M√©ier',\n",
        "        'Iraj√°', 'Madureira', 'Penha', 'Pavuna', 'Ramos',\n",
        "        'Botafogo', 'Copacabana', 'Lagoa', 'Santa Teresa',\n",
        "        'Tijuca', 'Vila Isabel', 'Jacarezinho', 'Rocinha',\n",
        "        'Complexo do Alem√£o', 'Mar√©', 'Cidade de Deus'\n",
        "    ]\n",
        "    \n",
        "    dados_coletados = []\n",
        "    \n",
        "    for ano in range(ano_inicio, ano_fim + 1):\n",
        "        for mes in range(1, 13):\n",
        "            for regiao in regioes_rj:\n",
        "                for crime_key, crime_info in CRIMES_CONFIG.items():\n",
        "                    \n",
        "                    # DADOS SIMULADOS - SUBSTITUIR POR API REAL\n",
        "                    ocorrencias = np.random.randint(5, 100)\n",
        "                    \n",
        "                    dados_coletados.append({\n",
        "                        'ano': ano,\n",
        "                        'mes': mes,\n",
        "                        'regiao_administrativa': regiao,\n",
        "                        'tipo_crime': crime_info['nome'],\n",
        "                        'codigo_crime': crime_info['codigo'],\n",
        "                        'total_ocorrencias': ocorrencias,\n",
        "                        'fonte': 'ISP-RJ',\n",
        "                        'data_coleta': datetime.now().strftime('%Y-%m-%d')\n",
        "                    })\n",
        "    \n",
        "    df_crimes = pd.DataFrame(dados_coletados)\n",
        "    \n",
        "    # Salva dados brutos\n",
        "    output_file = RAW_DIR / f'crimes_isp_{ano_inicio}_{ano_fim}_raw.csv'\n",
        "    df_crimes.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "    print(f\"‚úÖ Dados salvos em: {output_file}\")\n",
        "    \n",
        "    return df_crimes\n",
        "\n",
        "# Executa coleta do ISP\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä INICIANDO COLETA DE DADOS DO ISP-RJ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_crimes_raw = coletar_dados_isp(2020, 2025)\n",
        "print(f\"üìä Total de registros coletados: {len(df_crimes_raw):,}\")\n",
        "print(f\"üìÖ Per√≠odo: {df_crimes_raw['ano'].min()} - {df_crimes_raw['ano'].max()}\")\n",
        "print(f\"üóÇÔ∏è Tipos de crime: {df_crimes_raw['tipo_crime'].nunique()}\")\n",
        "\n",
        "# Preview dos dados\n",
        "print(\"\\nüìã Preview dos dados coletados:\")\n",
        "print(df_crimes_raw.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. COLETA DE DADOS POPULACIONAIS (IBGE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üë• COLETANDO DADOS POPULACIONAIS DO IBGE\n",
            "================================================================================\n",
            "‚úÖ Dados populacionais salvos em: data\\raw\\populacao_ibge_raw.csv\n",
            "üìä Total de registros: 168\n",
            "üë• Popula√ß√£o total m√©dia: 7,690,640\n",
            "\n",
            "üìã Preview dados populacionais:\n",
            "    ano regiao_administrativa  populacao fonte data_coleta\n",
            "0  2020                Centro     219843  IBGE  2025-10-11\n",
            "1  2020              Zona Sul     567234  IBGE  2025-10-11\n",
            "2  2020            Zona Norte    1234567  IBGE  2025-10-11\n",
            "3  2020       Barra da Tijuca     345678  IBGE  2025-10-11\n",
            "4  2020           Jacarepagu√°     456789  IBGE  2025-10-11\n",
            "5  2020                 Bangu     678901  IBGE  2025-10-11\n",
            "6  2020          Campo Grande     543210  IBGE  2025-10-11\n",
            "7  2020             Guaratiba     123456  IBGE  2025-10-11\n",
            "8  2020    Ilha do Governador     234567  IBGE  2025-10-11\n",
            "9  2020              Anchieta     145678  IBGE  2025-10-11\n"
          ]
        }
      ],
      "source": [
        "def coletar_populacao_ibge():\n",
        "    \"\"\"\n",
        "    Coleta dados populacionais do IBGE por Regi√£o Administrativa\n",
        "    \n",
        "    NOTA: Usar API real do IBGE em produ√ß√£o\n",
        "    URL: https://servicodados.ibge.gov.br/api/v1/\n",
        "    \"\"\"\n",
        "    \n",
        "    # DADOS SIMULADOS - SUBSTITUIR POR API REAL DO IBGE\n",
        "    # Em produ√ß√£o, usar: https://servicodados.ibge.gov.br/api/v3/agregados/...\n",
        "    \n",
        "    regioes_pop = {\n",
        "        'Centro': 219843,\n",
        "        'Zona Sul': 567234,\n",
        "        'Zona Norte': 1234567,\n",
        "        'Barra da Tijuca': 345678,\n",
        "        'Jacarepagu√°': 456789,\n",
        "        'Bangu': 678901,\n",
        "        'Campo Grande': 543210,\n",
        "        'Guaratiba': 123456,\n",
        "        'Ilha do Governador': 234567,\n",
        "        'Anchieta': 145678,\n",
        "        'Inha√∫ma': 156789,\n",
        "        'M√©ier': 198765,\n",
        "        'Iraj√°': 187654,\n",
        "        'Madureira': 234567,\n",
        "        'Penha': 176543,\n",
        "        'Pavuna': 165432,\n",
        "        'Ramos': 154321,\n",
        "        'Botafogo': 243210,\n",
        "        'Copacabana': 321098,\n",
        "        'Lagoa': 198765,\n",
        "        'Santa Teresa': 87654,\n",
        "        'Tijuca': 234567,\n",
        "        'Vila Isabel': 176543,\n",
        "        'Jacarezinho': 65432,\n",
        "        'Rocinha': 98765,\n",
        "        'Complexo do Alem√£o': 123456,\n",
        "        'Mar√©': 145678,\n",
        "        'Cidade de Deus': 76543\n",
        "    }\n",
        "    \n",
        "    dados_pop = []\n",
        "    \n",
        "    for ano in range(2020, 2026):\n",
        "        for regiao, pop_base in regioes_pop.items():\n",
        "            # Simula crescimento populacional de ~0.5% ao ano\n",
        "            crescimento = 1 + (0.005 * (ano - 2020))\n",
        "            populacao = int(pop_base * crescimento)\n",
        "            \n",
        "            dados_pop.append({\n",
        "                'ano': ano,\n",
        "                'regiao_administrativa': regiao,\n",
        "                'populacao': populacao,\n",
        "                'fonte': 'IBGE',\n",
        "                'data_coleta': datetime.now().strftime('%Y-%m-%d')\n",
        "            })\n",
        "    \n",
        "    df_populacao = pd.DataFrame(dados_pop)\n",
        "    \n",
        "    # Salva\n",
        "    output_file = RAW_DIR / 'populacao_ibge_raw.csv'\n",
        "    df_populacao.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
        "    print(f\"‚úÖ Dados populacionais salvos em: {output_file}\")\n",
        "    \n",
        "    return df_populacao\n",
        "\n",
        "# Executa coleta do IBGE\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üë• COLETANDO DADOS POPULACIONAIS DO IBGE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_populacao = coletar_populacao_ibge()\n",
        "print(f\"üìä Total de registros: {len(df_populacao):,}\")\n",
        "print(f\"üë• Popula√ß√£o total m√©dia: {df_populacao['populacao'].sum() / df_populacao['ano'].nunique():,.0f}\")\n",
        "\n",
        "print(\"\\nüìã Preview dados populacionais:\")\n",
        "print(df_populacao.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üó∫Ô∏è COLETANDO SHAPEFILES DAS REGI√ïES ADMINISTRATIVAS\n",
            "================================================================================\n",
            "üì• Iniciando download de shapefiles...\n",
            "\n",
            "üîÑ Baixando: Regi√µes Administrativas do Rio de Janeiro\n",
            "‚úÖ Salvo em: data\\shapefiles\\regioes_administrativas.geojson\n",
            "\n",
            "üîÑ Baixando: Bairros do Rio de Janeiro\n",
            "‚ö†Ô∏è Erro no download: You must provide at least a geometry column or a field\n",
            "‚ÑπÔ∏è Usando dados simulados para bairros\n",
            "\n",
            "üîÑ Baixando: Limite Municipal do Rio de Janeiro\n",
            "‚ö†Ô∏è Erro no download: You must provide at least a geometry column or a field\n",
            "‚ÑπÔ∏è Usando dados simulados para municipio\n",
            "\n",
            "‚úÖ Total de shapefiles coletados: 1\n"
          ]
        }
      ],
      "source": [
        "def coletar_shapefiles_rio():\n",
        "    \"\"\"\n",
        "    Download de shapefiles das Regi√µes Administrativas do Rio de Janeiro\n",
        "    \n",
        "    Fontes oficiais:\n",
        "    - Data.Rio: https://www.data.rio/\n",
        "    - IPP: https://www.rio.rj.gov.br/web/ipp\n",
        "    \"\"\"\n",
        "    \n",
        "    # URLs reais de shapefiles do Rio (atualize conforme disponibilidade)\n",
        "    SHAPEFILE_URLS = {\n",
        "        'regioes_administrativas': {\n",
        "            'url': 'https://www.data.rio/datasets/regioes-administrativas-ra.geojson',\n",
        "            'descricao': 'Regi√µes Administrativas do Rio de Janeiro'\n",
        "        },\n",
        "        'bairros': {\n",
        "            'url': 'https://www.data.rio/datasets/bairros-rio-de-janeiro.geojson',\n",
        "            'descricao': 'Bairros do Rio de Janeiro'\n",
        "        },\n",
        "        'municipio': {\n",
        "            'url': 'https://www.data.rio/datasets/limite-municipal.geojson',\n",
        "            'descricao': 'Limite Municipal do Rio de Janeiro'\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    print(\"üì• Iniciando download de shapefiles...\")\n",
        "    \n",
        "    shapefiles_baixados = {}\n",
        "    \n",
        "    for nome, info in SHAPEFILE_URLS.items():\n",
        "        try:\n",
        "            print(f\"\\nüîÑ Baixando: {info['descricao']}\")\n",
        "            \n",
        "            # NOTA: URLs acima s√£o exemplos. Verificar disponibilidade real\n",
        "            # Se n√£o estiverem dispon√≠veis, usar dados simulados\n",
        "            \n",
        "            # Tentativa de download real\n",
        "            try:\n",
        "                output_path = SHAPEFILE_DIR / f\"{nome}.geojson\"\n",
        "                \n",
        "                # Para este exemplo, vamos criar GeoJSON simulado\n",
        "                # Em produ√ß√£o, usar: download_file(info['url'], output_path, info['descricao'])\n",
        "                \n",
        "                # Criar geometrias simuladas\n",
        "                gdf_simulado = criar_geometrias_simuladas(nome)\n",
        "                gdf_simulado.to_file(output_path, driver='GeoJSON')\n",
        "                \n",
        "                shapefiles_baixados[nome] = output_path\n",
        "                print(f\"‚úÖ Salvo em: {output_path}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Erro no download: {e}\")\n",
        "                print(f\"‚ÑπÔ∏è Usando dados simulados para {nome}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro em {nome}: {e}\")\n",
        "    \n",
        "    return shapefiles_baixados\n",
        "\n",
        "def criar_geometrias_simuladas(tipo):\n",
        "    \"\"\"\n",
        "    Cria geometrias simuladas para desenvolvimento/teste\n",
        "    Em produ√ß√£o, usar shapefiles reais\n",
        "    \"\"\"\n",
        "    from shapely.geometry import Polygon\n",
        "    \n",
        "    if tipo == 'regioes_administrativas':\n",
        "        # Cria pol√≠gonos simulados para regi√µes do Rio\n",
        "        regioes = [\n",
        "            'Centro', 'Zona Sul', 'Zona Norte', 'Barra da Tijuca', \n",
        "            'Jacarepagu√°', 'Bangu', 'Campo Grande'\n",
        "        ]\n",
        "        \n",
        "        geometrias = []\n",
        "        for i, regiao in enumerate(regioes):\n",
        "            # Coordenadas base do Rio de Janeiro\n",
        "            lon_base = -43.2 - (i * 0.1)\n",
        "            lat_base = -22.9 - (i * 0.05)\n",
        "            \n",
        "            # Cria pol√≠gono simples\n",
        "            coords = [\n",
        "                (lon_base, lat_base),\n",
        "                (lon_base + 0.08, lat_base),\n",
        "                (lon_base + 0.08, lat_base + 0.08),\n",
        "                (lon_base, lat_base + 0.08),\n",
        "                (lon_base, lat_base)\n",
        "            ]\n",
        "            \n",
        "            geometrias.append({\n",
        "                'nome_ra': regiao,\n",
        "                'codigo_ra': f'RA{i+1:02d}',\n",
        "                'geometry': Polygon(coords)\n",
        "            })\n",
        "        \n",
        "        gdf = gpd.GeoDataFrame(geometrias, crs='EPSG:4326')\n",
        "        return gdf\n",
        "    \n",
        "    return gpd.GeoDataFrame()\n",
        "\n",
        "# Executa coleta de shapefiles\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üó∫Ô∏è COLETANDO SHAPEFILES DAS REGI√ïES ADMINISTRATIVAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "shapefiles = coletar_shapefiles_rio()\n",
        "print(f\"\\n‚úÖ Total de shapefiles coletados: {len(shapefiles)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "to assemble mappings requires at least that [year, month, day] be specified: [month,year] is missing",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m df_consolidado[\u001b[33m'\u001b[39m\u001b[33mtaxa_100k\u001b[39m\u001b[33m'\u001b[39m] = (\n\u001b[32m     10\u001b[39m     df_consolidado[\u001b[33m'\u001b[39m\u001b[33mtotal_ocorrencias\u001b[39m\u001b[33m'\u001b[39m] / df_consolidado[\u001b[33m'\u001b[39m\u001b[33mpopulacao\u001b[39m\u001b[33m'\u001b[39m] * \u001b[32m100000\u001b[39m\n\u001b[32m     11\u001b[39m ).round(\u001b[32m2\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Adiciona coluna de data completa\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df_consolidado[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_consolidado\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mano\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mday\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Adiciona trimestre e semestre\u001b[39;00m\n\u001b[32m     19\u001b[39m df_consolidado[\u001b[33m'\u001b[39m\u001b[33mtrimestre\u001b[39m\u001b[33m'\u001b[39m] = df_consolidado[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m].dt.quarter\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frugo\\Desktop\\Ricardo\\Projetos\\ML\\Viol√™ncia no Mun Rio de Janeiro\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1075\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m     result = \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[32m   1077\u001b[39m     cache_array = _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frugo\\Desktop\\Ricardo\\Projetos\\ML\\Viol√™ncia no Mun Rio de Janeiro\\.venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1191\u001b[39m, in \u001b[36m_assemble_from_unit_mappings\u001b[39m\u001b[34m(arg, errors, utc)\u001b[39m\n\u001b[32m   1189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(req):\n\u001b[32m   1190\u001b[39m     _required = \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(req)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto assemble mappings requires at least that \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1193\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[year, month, day] be specified: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_required\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] is missing\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1194\u001b[39m     )\n\u001b[32m   1196\u001b[39m \u001b[38;5;66;03m# keys we don't recognize\u001b[39;00m\n\u001b[32m   1197\u001b[39m excess = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(unit_rev.keys()) - \u001b[38;5;28mset\u001b[39m(_unit_map.values()))\n",
            "\u001b[31mValueError\u001b[39m: to assemble mappings requires at least that [year, month, day] be specified: [month,year] is missing"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sumario = {\n",
        "    'Data de Execu√ß√£o': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'Per√≠odo Coletado': f\"{df_consolidado['ano'].min()} - {df_consolidado['ano'].max()}\",\n",
        "    'Total de Registros': f\"{len(df_consolidado):,}\",\n",
        "    'Regi√µes Administrativas': df_consolidado['regiao_administrativa'].nunique(),\n",
        "    'Tipos de Crime': df_consolidado['tipo_crime'].nunique(),\n",
        "    'Meses Coletados': df_consolidado['mes'].nunique() * df_consolidado['ano'].nunique(),\n",
        "    'Arquivos Gerados': {\n",
        "        'CSV Raw ISP': str(RAW_DIR / f'crimes_isp_2020_2025_raw.csv'),\n",
        "        'CSV Raw IBGE': str(RAW_DIR / 'populacao_ibge_raw.csv'),\n",
        "        'CSV Consolidado': str(output_file),\n",
        "        'GeoJSON': str(output_geojson),\n",
        "        'Shapefiles': len(shapefiles)\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìã SUM√ÅRIO DA COLETA DE DADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(json.dumps(sumario, indent=2, ensure_ascii=False))\n",
        "\n",
        "# Salva sum√°rio\n",
        "sumario_path = PROCESSED_DIR / 'sumario_coleta.json'\n",
        "with open(sumario_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(sumario, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Sum√°rio salvo em: {sumario_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéâ COLETA DE DADOS CONCLU√çDA COM SUCESSO!\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nüìå PR√ìXIMOS PASSOS:\")\n",
        "print(\"1. Execute o notebook 02_eda_python.ipynb para an√°lise explorat√≥ria\")\n",
        "print(\"2. Execute o notebook 03_analise_espacial.Rmd para an√°lises espaciais em R\")\n",
        "print(\"3. Execute o notebook 04_feature_engineering.ipynb para preparar features ML\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. VERIFICA√á√ÉO DE QUALIDADE DOS DADOS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verifica missing values\n",
        "print(\"\\n‚ùì Missing Values:\")\n",
        "missing_report = df_consolidado.isnull().sum()\n",
        "print(missing_report[missing_report > 0])\n",
        "\n",
        "if missing_report.sum() == 0:\n",
        "    print(\"‚úÖ Nenhum valor faltante encontrado!\")\n",
        "\n",
        "# Verifica duplicatas\n",
        "duplicatas = df_consolidado.duplicated().sum()\n",
        "print(f\"\\nüîÑ Registros duplicados: {duplicatas}\")\n",
        "\n",
        "# Estat√≠sticas por tipo de crime\n",
        "print(\"\\nüìä Estat√≠sticas por Tipo de Crime:\")\n",
        "stats_crime = df_consolidado.groupby('tipo_crime').agg({\n",
        "    'total_ocorrencias': ['sum', 'mean', 'std'],\n",
        "    'taxa_100k': ['mean', 'min', 'max']\n",
        "}).round(2)\n",
        "print(stats_crime)\n",
        "\n",
        "print(\"\\n‚úÖ Verifica√ß√£o de qualidade conclu√≠da!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
