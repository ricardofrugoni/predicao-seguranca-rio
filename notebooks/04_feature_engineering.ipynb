{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - Feature Engineering - Viol√™ncia no Rio de Janeiro\n",
        "\n",
        "Este notebook realiza feature engineering completo para preparar dados para modelagem de machine learning, incluindo:\n",
        "\n",
        "## Objetivos do Feature Engineering\n",
        "\n",
        "1. **Features Temporais**: Lags, m√©dias m√≥veis, sazonalidade\n",
        "2. **Features Espaciais**: Dist√¢ncias, densidades, vizinhan√ßa\n",
        "3. **Features Socioecon√¥micas**: √çndices, indicadores, rankings\n",
        "4. **Features de Intera√ß√£o**: Combina√ß√µes entre vari√°veis\n",
        "5. **Features de Agrega√ß√£o**: Estat√≠sticas por regi√£o e per√≠odo\n",
        "\n",
        "## Estrutura do Feature Engineering\n",
        "\n",
        "- **Se√ß√£o 1**: Carregamento e prepara√ß√£o dos dados\n",
        "- **Se√ß√£o 2**: Features temporais (lags, m√©dias m√≥veis, sazonalidade)\n",
        "- **Se√ß√£o 3**: Features espaciais (dist√¢ncias, densidades, vizinhan√ßa)\n",
        "- **Se√ß√£o 4**: Features socioecon√¥micas (√≠ndices, indicadores)\n",
        "- **Se√ß√£o 5**: Features de intera√ß√£o e agrega√ß√£o\n",
        "- **Se√ß√£o 6**: Sele√ß√£o e valida√ß√£o de features\n",
        "- **Se√ß√£o 7**: Prepara√ß√£o para modelagem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 1. IMPORTA√á√ÉO DE BIBLIOTECAS E CONFIGURA√á√ÉO\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configura√ß√£o\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "# Configura√ß√£o de diret√≥rios\n",
        "BASE_DIR = Path('.')\n",
        "DATA_DIR = BASE_DIR / 'data'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "OUTPUT_DIR = BASE_DIR / 'outputs' / 'figures'\n",
        "\n",
        "# Cria diret√≥rio de sa√≠da\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
        "print(f\"üìÅ Diret√≥rio de sa√≠da: {OUTPUT_DIR.absolute()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carrega dados consolidados\n",
        "df_crimes = pd.read_csv(PROCESSED_DIR / 'crimes_consolidado.csv')\n",
        "print(f\"üìä Dados carregados: {len(df_crimes):,} registros\")\n",
        "\n",
        "# Carrega dados geoespaciais\n",
        "gdf_crimes = gpd.read_file(PROCESSED_DIR / 'crimes_geo.geojson')\n",
        "print(f\"üó∫Ô∏è Dados geoespaciais: {len(gdf_crimes):,} registros\")\n",
        "\n",
        "# Converte coluna de data\n",
        "df_crimes['data'] = pd.to_datetime(df_crimes['data'])\n",
        "\n",
        "# Informa√ß√µes b√°sicas\n",
        "print(\"\\nüìã INFORMA√á√ïES B√ÅSICAS:\")\n",
        "print(f\"Per√≠odo: {df_crimes['ano'].min()} - {df_crimes['ano'].max()}\")\n",
        "print(f\"Regi√µes: {df_crimes['regiao_administrativa'].nunique()}\")\n",
        "print(f\"Tipos de crime: {df_crimes['tipo_crime'].nunique()}\")\n",
        "print(f\"Colunas: {list(df_crimes.columns)}\")\n",
        "\n",
        "# Preview dos dados\n",
        "print(\"\\nüìã Preview dos dados:\")\n",
        "print(df_crimes.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. FEATURES TEMPORAIS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cria features temporais\n",
        "def create_temporal_features(df):\n",
        "    \"\"\"\n",
        "    Cria features temporais para an√°lise de s√©ries temporais\n",
        "    \"\"\"\n",
        "    df_features = df.copy()\n",
        "    \n",
        "    # Features b√°sicas de tempo\n",
        "    df_features['ano'] = df_features['data'].dt.year\n",
        "    df_features['mes'] = df_features['data'].dt.month\n",
        "    df_features['dia'] = df_features['data'].dt.day\n",
        "    df_features['dia_semana'] = df_features['data'].dt.dayofweek\n",
        "    df_features['dia_ano'] = df_features['data'].dt.dayofyear\n",
        "    df_features['trimestre'] = df_features['data'].dt.quarter\n",
        "    df_features['semestre'] = df_features['data'].dt.month.apply(lambda x: 1 if x <= 6 else 2)\n",
        "    \n",
        "    # Features c√≠clicas\n",
        "    df_features['mes_sin'] = np.sin(2 * np.pi * df_features['mes'] / 12)\n",
        "    df_features['mes_cos'] = np.cos(2 * np.pi * df_features['mes'] / 12)\n",
        "    df_features['dia_semana_sin'] = np.sin(2 * np.pi * df_features['dia_semana'] / 7)\n",
        "    df_features['dia_semana_cos'] = np.cos(2 * np.pi * df_features['dia_semana'] / 7)\n",
        "    \n",
        "    # Features de sazonalidade\n",
        "    df_features['eh_fim_semana'] = df_features['dia_semana'].isin([5, 6]).astype(int)\n",
        "    df_features['eh_feriado'] = 0  # Implementar l√≥gica de feriados\n",
        "    df_features['eh_vacacao'] = df_features['mes'].isin([12, 1, 2, 7]).astype(int)\n",
        "    \n",
        "    return df_features\n",
        "\n",
        "# Aplica features temporais\n",
        "df_crimes = create_temporal_features(df_crimes)\n",
        "\n",
        "print(\"‚úÖ Features temporais criadas\")\n",
        "print(f\"üìä Total de colunas: {len(df_crimes.columns)}\")\n",
        "\n",
        "# Mostra novas features\n",
        "temporal_features = ['ano', 'mes', 'dia', 'dia_semana', 'trimestre', 'semestre', \n",
        "                    'mes_sin', 'mes_cos', 'dia_semana_sin', 'dia_semana_cos',\n",
        "                    'eh_fim_semana', 'eh_vacacao']\n",
        "\n",
        "print(\"\\nüìã Features temporais criadas:\")\n",
        "for feature in temporal_features:\n",
        "    if feature in df_crimes.columns:\n",
        "        print(f\"  - {feature}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cria features de lag e m√©dias m√≥veis\n",
        "def create_lag_features(df, group_cols, value_col, lags=[1, 3, 6, 12]):\n",
        "    \"\"\"\n",
        "    Cria features de lag e m√©dias m√≥veis\n",
        "    \"\"\"\n",
        "    df_features = df.copy()\n",
        "    \n",
        "    # Ordena por grupo e data\n",
        "    df_features = df_features.sort_values(group_cols + ['data'])\n",
        "    \n",
        "    # Cria lags\n",
        "    for lag in lags:\n",
        "        df_features[f'{value_col}_lag_{lag}'] = df_features.groupby(group_cols)[value_col].shift(lag)\n",
        "    \n",
        "    # Cria m√©dias m√≥veis\n",
        "    for window in [3, 6, 12]:\n",
        "        df_features[f'{value_col}_ma_{window}'] = df_features.groupby(group_cols)[value_col].rolling(window=window).mean().reset_index(0, drop=True)\n",
        "    \n",
        "    # Cria diferen√ßas\n",
        "    df_features[f'{value_col}_diff'] = df_features.groupby(group_cols)[value_col].diff()\n",
        "    df_features[f'{value_col}_diff2'] = df_features.groupby(group_cols)[value_col].diff(2)\n",
        "    \n",
        "    # Cria features de tend√™ncia\n",
        "    df_features[f'{value_col}_trend_3m'] = df_features.groupby(group_cols)[value_col].rolling(window=3).apply(lambda x: np.polyfit(range(len(x)), x, 1)[0]).reset_index(0, drop=True)\n",
        "    \n",
        "    return df_features\n",
        "\n",
        "# Aplica features de lag\n",
        "df_crimes = create_lag_features(df_crimes, \n",
        "                               group_cols=['regiao_administrativa', 'tipo_crime'],\n",
        "                               value_col='total_ocorrencias')\n",
        "\n",
        "print(\"‚úÖ Features de lag e m√©dias m√≥veis criadas\")\n",
        "\n",
        "# Mostra features de lag criadas\n",
        "lag_features = [col for col in df_crimes.columns if 'lag_' in col or 'ma_' in col or 'diff' in col or 'trend' in col]\n",
        "print(f\"\\nüìã Features de lag criadas: {len(lag_features)}\")\n",
        "for feature in lag_features[:10]:  # Mostra primeiras 10\n",
        "    print(f\"  - {feature}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. FEATURES ESPACIAIS\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
